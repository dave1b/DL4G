{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example for a simple neural network\n",
    "\n",
    "## Trump by maximum color (2 colors)\n",
    "\n",
    "The inputs to the network are the number of cards of each color. The network should learn to select the color with the largest number of cards of that color.\n",
    "\n",
    "For a simple example, let us assume that there are 5 cards in total for a player and only 2 colors.\n",
    "\n",
    "### Libraries\n",
    "\n",
    "We use the keras library for building, training and evaluating the network. A tutorial for keras can be found on (https://keras.io/) or https://www.tensorflow.org/guide/keras. There are different implementations of keras, here I will use the one build on tensorflow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output function\n",
    "\n",
    "We have to encode the output somehow, for two classes, the simplest solution is a single variable that should be 0 if there are more cards of color 0 and 1 if there are more cards of color 1.\n",
    "\n",
    "### Training and label data.\n",
    "\n",
    "So we can prepare some training data. In this simple case, all the possible configurations are actually known.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 5.]\n",
      " [1. 4.]\n",
      " [2. 3.]\n",
      " [3. 2.]\n",
      " [4. 1.]\n",
      " [5. 0.]]\n",
      "[1. 1. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "x_train = np.array([\n",
    "    [0, 5],\n",
    "    [1, 4],\n",
    "    [2, 3],\n",
    "    [3, 2],\n",
    "    [4, 1],\n",
    "    [5, 0],\n",
    "], dtype=np.float32)\n",
    "y_train = np.array([1, 1, 1, 0, 0, 0, ], dtype=np.float32)\n",
    "print(x_train)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalisation\n",
    "\n",
    "Input data can have different ranges. It is always a good idea (in other words absolutely essential) to normalize the input data. This is usually done into the range 0..1 or -1..1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.  1. ]\n",
      " [0.2 0.8]\n",
      " [0.4 0.6]\n",
      " [0.6 0.4]\n",
      " [0.8 0.2]\n",
      " [1.  0. ]]\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train / 5.0\n",
    "print(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A first network.\n",
    "\n",
    "We will start with a very simple network, where we connect the inputs directly to the output. So there will be 2 variables, the weights for the connection and the bias. The output function is a sigmoid, which takes values between 0 and 1.\n",
    "\n",
    "With keras, we first have to create the type of model we want (Sequential), and can then add layers. In the tensorflow implementation, we have to add the input_shape parameter in the first layer to tell it the format of the input. This does not include the batch dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid', input_shape=[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we have to compile the model and tell it what loss function and optimizer we want to have. We will take a mean squared error for loss function first. (This is actually not optimal and will be corrected in an exercise).\n",
    "\n",
    "Besides the loss, we usually want to look at some metrics. Here we choose accuracy, that measures how often the network makes the correct decision (see last lecture)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can print some details about the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_21 (Dense)            (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3\n",
      "Trainable params: 3\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "[array([[0.68495166],\n",
      "       [0.32549334]], dtype=float32), array([0.], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "print(model.get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can either train one batch, or we can use fit to train repeatedly. The result from the training is the loss function and the metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[0.2912900447845459, 0.5]"
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train_on_batch(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now try to fit the data in minibatches multiple times. This will calculate the weights, so as to minimize the loss. We might not always get a good result in the first try and even this very simple network seems to need a large number of training steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2911 - accuracy: 0.5000\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2910 - accuracy: 0.5000\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2908 - accuracy: 0.5000\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2907 - accuracy: 0.5000\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2905 - accuracy: 0.5000\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2904 - accuracy: 0.5000\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2902 - accuracy: 0.5000\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2901 - accuracy: 0.5000\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2900 - accuracy: 0.5000\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2898 - accuracy: 0.5000\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2897 - accuracy: 0.5000\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2895 - accuracy: 0.5000\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2894 - accuracy: 0.5000\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2892 - accuracy: 0.5000\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2891 - accuracy: 0.5000\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2889 - accuracy: 0.5000\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2888 - accuracy: 0.5000\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2886 - accuracy: 0.5000\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2885 - accuracy: 0.5000\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2883 - accuracy: 0.5000\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2882 - accuracy: 0.5000\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2880 - accuracy: 0.5000\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2879 - accuracy: 0.5000\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2877 - accuracy: 0.5000\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2876 - accuracy: 0.5000\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2874 - accuracy: 0.5000\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2873 - accuracy: 0.5000\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2871 - accuracy: 0.5000\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2870 - accuracy: 0.5000\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2868 - accuracy: 0.5000\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2867 - accuracy: 0.5000\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2865 - accuracy: 0.5000\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2864 - accuracy: 0.5000\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2863 - accuracy: 0.5000\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2861 - accuracy: 0.5000\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2860 - accuracy: 0.5000\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2858 - accuracy: 0.5000\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2857 - accuracy: 0.5000\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2855 - accuracy: 0.5000\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2854 - accuracy: 0.5000\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2852 - accuracy: 0.5000\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2851 - accuracy: 0.5000\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2849 - accuracy: 0.5000\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2848 - accuracy: 0.5000\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2846 - accuracy: 0.5000\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2845 - accuracy: 0.5000\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2843 - accuracy: 0.5000\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2842 - accuracy: 0.5000\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2841 - accuracy: 0.5000\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2839 - accuracy: 0.5000\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2838 - accuracy: 0.5000\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2836 - accuracy: 0.5000\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2835 - accuracy: 0.5000\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2833 - accuracy: 0.5000\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2832 - accuracy: 0.5000\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2830 - accuracy: 0.5000\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2829 - accuracy: 0.5000\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2827 - accuracy: 0.5000\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2826 - accuracy: 0.5000\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2824 - accuracy: 0.5000\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2823 - accuracy: 0.5000\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2822 - accuracy: 0.5000\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2820 - accuracy: 0.5000\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2819 - accuracy: 0.5000\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2817 - accuracy: 0.5000\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2816 - accuracy: 0.5000\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2814 - accuracy: 0.5000\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2813 - accuracy: 0.5000\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2811 - accuracy: 0.5000\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2810 - accuracy: 0.5000\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2808 - accuracy: 0.5000\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2807 - accuracy: 0.5000\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2806 - accuracy: 0.5000\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2804 - accuracy: 0.5000\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2803 - accuracy: 0.5000\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2801 - accuracy: 0.5000\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2800 - accuracy: 0.5000\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2798 - accuracy: 0.5000\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2797 - accuracy: 0.5000\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2795 - accuracy: 0.5000\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2794 - accuracy: 0.5000\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2793 - accuracy: 0.5000\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2791 - accuracy: 0.5000\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2790 - accuracy: 0.5000\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2788 - accuracy: 0.5000\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2787 - accuracy: 0.5000\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2785 - accuracy: 0.5000\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2784 - accuracy: 0.5000\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2782 - accuracy: 0.5000\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2781 - accuracy: 0.5000\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2780 - accuracy: 0.5000\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2778 - accuracy: 0.5000\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2777 - accuracy: 0.5000\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2775 - accuracy: 0.5000\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2774 - accuracy: 0.5000\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2772 - accuracy: 0.5000\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2771 - accuracy: 0.5000\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2770 - accuracy: 0.5000\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2768 - accuracy: 0.5000\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2767 - accuracy: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x27ddce47f40>"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=100, batch_size=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can predict the values from the training value. Why are the results floating point number and not 0 or 1? Does the result seem likely?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 36ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[0.58072937],\n       [0.59090716],\n       [0.6010077 ],\n       [0.61102295],\n       [0.6209454 ],\n       [0.63076764]], dtype=float32)"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also print the found weights for each layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense_21\n",
      "[array([[0.58523333],\n",
      "       [0.37549004]], dtype=float32), array([-0.04972177], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    weights = layer.get_weights()\n",
    "    print(layer.name)\n",
    "    print(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we find the actual predictions? We use a threshold on the output of the sigmoid function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[ True],\n       [ True],\n       [ True],\n       [ True],\n       [ True],\n       [ True]])"
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_train) > 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A larger network\n",
    "\n",
    "Lets try a more complicated network with two hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(2, activation='relu', input_shape=[2]))  # hidden\n",
    "model.add(keras.layers.Dense(2, activation='relu'))  # hidden\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))  # output\n",
    "model.compile(loss='mse',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And train it again..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.3020 - accuracy: 0.1667\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3015 - accuracy: 0.1667\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3009 - accuracy: 0.1667\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3004 - accuracy: 0.1667\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2999 - accuracy: 0.1667\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2994 - accuracy: 0.1667\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2989 - accuracy: 0.1667\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2984 - accuracy: 0.1667\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2979 - accuracy: 0.1667\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2974 - accuracy: 0.1667\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2968 - accuracy: 0.1667\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2963 - accuracy: 0.1667\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2958 - accuracy: 0.1667\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2953 - accuracy: 0.1667\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2949 - accuracy: 0.1667\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2944 - accuracy: 0.1667\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2939 - accuracy: 0.1667\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2934 - accuracy: 0.1667\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2929 - accuracy: 0.1667\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2924 - accuracy: 0.1667\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2919 - accuracy: 0.1667\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2914 - accuracy: 0.1667\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2910 - accuracy: 0.1667\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2905 - accuracy: 0.1667\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2900 - accuracy: 0.1667\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2895 - accuracy: 0.1667\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2890 - accuracy: 0.1667\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2886 - accuracy: 0.1667\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2881 - accuracy: 0.1667\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2876 - accuracy: 0.1667\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2872 - accuracy: 0.1667\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2867 - accuracy: 0.1667\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2863 - accuracy: 0.1667\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2858 - accuracy: 0.1667\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2853 - accuracy: 0.1667\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2849 - accuracy: 0.1667\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2844 - accuracy: 0.1667\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2840 - accuracy: 0.1667\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2835 - accuracy: 0.1667\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2831 - accuracy: 0.1667\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2827 - accuracy: 0.1667\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2823 - accuracy: 0.1667\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2819 - accuracy: 0.1667\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2815 - accuracy: 0.1667\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2812 - accuracy: 0.1667\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2808 - accuracy: 0.1667\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2804 - accuracy: 0.1667\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2800 - accuracy: 0.1667\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2796 - accuracy: 0.1667\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2793 - accuracy: 0.1667\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2789 - accuracy: 0.1667\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2785 - accuracy: 0.1667\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2782 - accuracy: 0.1667\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2778 - accuracy: 0.1667\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2774 - accuracy: 0.1667\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2771 - accuracy: 0.1667\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2767 - accuracy: 0.1667\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2763 - accuracy: 0.1667\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2760 - accuracy: 0.1667\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2756 - accuracy: 0.1667\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2753 - accuracy: 0.1667\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2749 - accuracy: 0.1667\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2745 - accuracy: 0.1667\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2742 - accuracy: 0.1667\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2738 - accuracy: 0.1667\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2735 - accuracy: 0.1667\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2731 - accuracy: 0.1667\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2728 - accuracy: 0.1667\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2724 - accuracy: 0.1667\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2721 - accuracy: 0.1667\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2717 - accuracy: 0.1667\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2714 - accuracy: 0.1667\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2711 - accuracy: 0.1667\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2707 - accuracy: 0.1667\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2704 - accuracy: 0.1667\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2700 - accuracy: 0.1667\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2697 - accuracy: 0.1667\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2694 - accuracy: 0.1667\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2690 - accuracy: 0.1667\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2687 - accuracy: 0.1667\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2684 - accuracy: 0.1667\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2681 - accuracy: 0.1667\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2677 - accuracy: 0.1667\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2674 - accuracy: 0.1667\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2671 - accuracy: 0.1667\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2668 - accuracy: 0.1667\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2664 - accuracy: 0.1667\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2661 - accuracy: 0.1667\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2658 - accuracy: 0.1667\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2655 - accuracy: 0.1667\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2652 - accuracy: 0.3333\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2648 - accuracy: 0.3333\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2645 - accuracy: 0.3333\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2643 - accuracy: 0.3333\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2641 - accuracy: 0.3333\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2640 - accuracy: 0.3333\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2639 - accuracy: 0.3333\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2638 - accuracy: 0.3333\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2637 - accuracy: 0.3333\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2636 - accuracy: 0.3333\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2635 - accuracy: 0.3333\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2634 - accuracy: 0.3333\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2633 - accuracy: 0.3333\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2632 - accuracy: 0.3333\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2632 - accuracy: 0.3333\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2631 - accuracy: 0.3333\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2630 - accuracy: 0.3333\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2629 - accuracy: 0.3333\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2628 - accuracy: 0.3333\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2627 - accuracy: 0.3333\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2626 - accuracy: 0.3333\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2625 - accuracy: 0.3333\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2625 - accuracy: 0.3333\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2624 - accuracy: 0.3333\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2623 - accuracy: 0.3333\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2622 - accuracy: 0.3333\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2621 - accuracy: 0.3333\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2620 - accuracy: 0.3333\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2619 - accuracy: 0.3333\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2618 - accuracy: 0.3333\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2618 - accuracy: 0.3333\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2617 - accuracy: 0.3333\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2616 - accuracy: 0.3333\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2615 - accuracy: 0.3333\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2614 - accuracy: 0.3333\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2613 - accuracy: 0.3333\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2613 - accuracy: 0.3333\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2612 - accuracy: 0.3333\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2611 - accuracy: 0.3333\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2610 - accuracy: 0.3333\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2609 - accuracy: 0.3333\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2608 - accuracy: 0.3333\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2608 - accuracy: 0.3333\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2607 - accuracy: 0.3333\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2606 - accuracy: 0.3333\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2605 - accuracy: 0.3333\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2604 - accuracy: 0.3333\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2603 - accuracy: 0.3333\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2603 - accuracy: 0.3333\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2602 - accuracy: 0.3333\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2601 - accuracy: 0.3333\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2600 - accuracy: 0.3333\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2599 - accuracy: 0.3333\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2599 - accuracy: 0.3333\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2598 - accuracy: 0.3333\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2597 - accuracy: 0.3333\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2596 - accuracy: 0.3333\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2595 - accuracy: 0.3333\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2594 - accuracy: 0.3333\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2594 - accuracy: 0.3333\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2593 - accuracy: 0.3333\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2592 - accuracy: 0.3333\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2591 - accuracy: 0.3333\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2591 - accuracy: 0.3333\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2590 - accuracy: 0.3333\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2589 - accuracy: 0.3333\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2588 - accuracy: 0.3333\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2587 - accuracy: 0.3333\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2587 - accuracy: 0.3333\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.2586 - accuracy: 0.3333\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2585 - accuracy: 0.3333\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2584 - accuracy: 0.3333\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2583 - accuracy: 0.3333\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2583 - accuracy: 0.3333\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2582 - accuracy: 0.3333\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2581 - accuracy: 0.3333\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2580 - accuracy: 0.3333\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2580 - accuracy: 0.3333\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2579 - accuracy: 0.3333\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2578 - accuracy: 0.3333\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2577 - accuracy: 0.3333\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2577 - accuracy: 0.3333\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2576 - accuracy: 0.3333\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2575 - accuracy: 0.3333\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2574 - accuracy: 0.3333\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2574 - accuracy: 0.3333\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2573 - accuracy: 0.3333\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2572 - accuracy: 0.3333\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2571 - accuracy: 0.3333\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2571 - accuracy: 0.3333\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2570 - accuracy: 0.3333\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2569 - accuracy: 0.3333\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2568 - accuracy: 0.3333\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2568 - accuracy: 0.3333\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2567 - accuracy: 0.3333\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2566 - accuracy: 0.3333\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2565 - accuracy: 0.3333\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2565 - accuracy: 0.3333\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2564 - accuracy: 0.3333\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2563 - accuracy: 0.3333\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2562 - accuracy: 0.3333\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2562 - accuracy: 0.3333\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2561 - accuracy: 0.3333\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2560 - accuracy: 0.3333\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2559 - accuracy: 0.3333\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2559 - accuracy: 0.3333\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2558 - accuracy: 0.3333\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2557 - accuracy: 0.3333\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2557 - accuracy: 0.3333\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2556 - accuracy: 0.3333\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x27ddcea88b0>"
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=200, batch_size=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are not necessarly better, how does the prediction look now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000027DDCEDD040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 44ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[0.49708238],\n       [0.49708238],\n       [0.49708238],\n       [0.49708238],\n       [0.49708238],\n       [0.5292833 ]], dtype=float32)"
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.layers.core.dense.Dense object at 0x0000027DDCEA8A00>\n",
      "[array([[ 0.6028108, -0.965752 ],\n",
      "       [-1.191112 , -0.1566987]], dtype=float32), array([-0.12573428,  0.        ], dtype=float32)]\n",
      "<keras.layers.core.dense.Dense object at 0x0000027DDCEA82B0>\n",
      "[array([[ 0.09312582,  0.5909856 ],\n",
      "       [ 0.77801263, -0.3098777 ]], dtype=float32), array([-0.05180462, -0.18868946], dtype=float32)]\n",
      "<keras.layers.core.dense.Dense object at 0x0000027DDC1B4AC0>\n",
      "[array([[0.7886322],\n",
      "       [1.3826257]], dtype=float32), array([-0.01167064], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    weights = layer.get_weights()\n",
    "    print(layer)\n",
    "    print(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The larger network, does not seem to work better as the simpler one. Or is it maybe not large enough?\n",
    "\n",
    "The problem is not the network, but the data, we just do not have enough data. So lets try to make up some more data artificially.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_new = np.random.random(size=(10000, 2))\n",
    "y_new = np.zeros(10000, dtype=np.float32)\n",
    "condition = (x_new[:, 1] > x_new[:, 0])\n",
    "y_new[condition] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 976us/step - loss: 0.2501 - accuracy: 0.4961\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 861us/step - loss: 0.2501 - accuracy: 0.4996\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 819us/step - loss: 0.2500 - accuracy: 0.5013\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 823us/step - loss: 0.2500 - accuracy: 0.5023\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 844us/step - loss: 0.2500 - accuracy: 0.5033\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 798us/step - loss: 0.2500 - accuracy: 0.5045\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 801us/step - loss: 0.2500 - accuracy: 0.5049\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 759us/step - loss: 0.2500 - accuracy: 0.5056\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 804us/step - loss: 0.2500 - accuracy: 0.5062\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 763us/step - loss: 0.2500 - accuracy: 0.5067\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 788us/step - loss: 0.2500 - accuracy: 0.5073\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 752us/step - loss: 0.2500 - accuracy: 0.5074\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 753us/step - loss: 0.2500 - accuracy: 0.5076\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 774us/step - loss: 0.2499 - accuracy: 0.5077\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 883us/step - loss: 0.2499 - accuracy: 0.5077\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 809us/step - loss: 0.2499 - accuracy: 0.5077\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 758us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 733us/step - loss: 0.2499 - accuracy: 0.5078\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 773us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 788us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 778us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 788us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 914us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 942us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 960us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 890us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 864us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 753us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 834us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 788us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 753us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 750us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 753us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 743us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 778us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 773us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 773us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 792us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 727us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 768us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 758us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 763us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 763us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 758us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 732us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 732us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 738us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 768us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 748us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 748us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 751us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 844us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 823us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 828us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 803us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 753us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 768us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 737us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 740us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 788us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 724us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 837us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 758us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 773us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 762us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 975us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 990us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 920us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 910us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 904us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 975us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 879us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 854us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 808us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 793us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 788us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 783us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 813us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - 0s 849us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - 0s 859us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - 0s 813us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - 0s 783us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - 0s 758us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - 0s 748us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - 0s 737us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - 0s 799us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - 0s 753us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - 0s 753us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - 0s 743us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 90/100\n",
      "100/100 [==============================] - 0s 758us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 91/100\n",
      "100/100 [==============================] - 0s 763us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 92/100\n",
      "100/100 [==============================] - 0s 758us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 93/100\n",
      "100/100 [==============================] - 0s 823us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 94/100\n",
      "100/100 [==============================] - 0s 763us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 95/100\n",
      "100/100 [==============================] - 0s 747us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 96/100\n",
      "100/100 [==============================] - 0s 770us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 97/100\n",
      "100/100 [==============================] - 0s 768us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 98/100\n",
      "100/100 [==============================] - 0s 788us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 99/100\n",
      "100/100 [==============================] - 0s 768us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 100/100\n",
      "100/100 [==============================] - 0s 768us/step - loss: 0.2499 - accuracy: 0.5079\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x27ddcf5a040>"
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_new, y_new, epochs=100, batch_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That seems better. Lets look how it performs on our original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[0.49201426],\n       [0.49201426],\n       [0.49201426],\n       [0.49201426],\n       [0.49201426],\n       [0.49572238]], dtype=float32)"
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "We might want to check how the network performs on any data. For this, keras provides the evaluate function that will \n",
    "evaluate the loss and the metrics. So of course label (y) data is needed for that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 667us/step - loss: 0.2499 - accuracy: 0.5079\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.24993766844272614, 0.5078999996185303]"
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_new, y_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, we would normally do that on validation or test data not used during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 751us/step - loss: 0.2501 - accuracy: 0.4996\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.250071257352829, 0.49959999322891235]"
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val_new = np.random.random(size=(5000, 2))\n",
    "y_val_new = np.zeros(5000, dtype=np.float32)\n",
    "y_val_new[x_val_new[:, 1] > x_val_new[:, 0]] = 1.0\n",
    "model.evaluate(x_val_new, y_val_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation\n",
    "\n",
    "It is essential to visualise the training process to see what is going on. In Keras, an easy method to do this is to use the history object that is returned from fit. It contains the metrics and the loss.\n",
    "\n",
    "We will also split our data into training and validation for this test. We rebuild the model, so that it is initialized again. Otherwise we would just continue with the weights from the previous fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.2497 - accuracy: 0.5075 - val_loss: 0.2497 - val_accuracy: 0.5088\n",
      "Epoch 2/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2497 - accuracy: 0.5076 - val_loss: 0.2497 - val_accuracy: 0.5088\n",
      "Epoch 3/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2497 - accuracy: 0.5076 - val_loss: 0.2497 - val_accuracy: 0.5088\n",
      "Epoch 4/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2496 - accuracy: 0.5076 - val_loss: 0.2496 - val_accuracy: 0.5088\n",
      "Epoch 5/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2496 - accuracy: 0.5076 - val_loss: 0.2496 - val_accuracy: 0.5088\n",
      "Epoch 6/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2496 - accuracy: 0.5076 - val_loss: 0.2496 - val_accuracy: 0.5088\n",
      "Epoch 7/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2495 - accuracy: 0.5076 - val_loss: 0.2495 - val_accuracy: 0.5088\n",
      "Epoch 8/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2495 - accuracy: 0.5076 - val_loss: 0.2495 - val_accuracy: 0.5088\n",
      "Epoch 9/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2494 - accuracy: 0.5076 - val_loss: 0.2494 - val_accuracy: 0.5088\n",
      "Epoch 10/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2493 - accuracy: 0.5076 - val_loss: 0.2493 - val_accuracy: 0.5088\n",
      "Epoch 11/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2493 - accuracy: 0.5076 - val_loss: 0.2493 - val_accuracy: 0.5088\n",
      "Epoch 12/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2492 - accuracy: 0.5076 - val_loss: 0.2492 - val_accuracy: 0.5088\n",
      "Epoch 13/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2491 - accuracy: 0.5076 - val_loss: 0.2491 - val_accuracy: 0.5088\n",
      "Epoch 14/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2490 - accuracy: 0.5076 - val_loss: 0.2490 - val_accuracy: 0.5088\n",
      "Epoch 15/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2489 - accuracy: 0.5076 - val_loss: 0.2489 - val_accuracy: 0.5088\n",
      "Epoch 16/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2487 - accuracy: 0.5076 - val_loss: 0.2487 - val_accuracy: 0.5088\n",
      "Epoch 17/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2486 - accuracy: 0.5076 - val_loss: 0.2486 - val_accuracy: 0.5088\n",
      "Epoch 18/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2484 - accuracy: 0.5076 - val_loss: 0.2484 - val_accuracy: 0.5088\n",
      "Epoch 19/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2482 - accuracy: 0.5076 - val_loss: 0.2482 - val_accuracy: 0.5088\n",
      "Epoch 20/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2479 - accuracy: 0.5076 - val_loss: 0.2479 - val_accuracy: 0.5088\n",
      "Epoch 21/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2476 - accuracy: 0.5076 - val_loss: 0.2476 - val_accuracy: 0.5088\n",
      "Epoch 22/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2473 - accuracy: 0.5076 - val_loss: 0.2473 - val_accuracy: 0.5088\n",
      "Epoch 23/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2469 - accuracy: 0.5076 - val_loss: 0.2469 - val_accuracy: 0.5088\n",
      "Epoch 24/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2464 - accuracy: 0.5076 - val_loss: 0.2464 - val_accuracy: 0.5088\n",
      "Epoch 25/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2459 - accuracy: 0.5076 - val_loss: 0.2458 - val_accuracy: 0.5088\n",
      "Epoch 26/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2452 - accuracy: 0.5076 - val_loss: 0.2452 - val_accuracy: 0.5088\n",
      "Epoch 27/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2444 - accuracy: 0.5076 - val_loss: 0.2444 - val_accuracy: 0.5088\n",
      "Epoch 28/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2435 - accuracy: 0.5076 - val_loss: 0.2434 - val_accuracy: 0.5088\n",
      "Epoch 29/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2424 - accuracy: 0.5076 - val_loss: 0.2422 - val_accuracy: 0.5088\n",
      "Epoch 30/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2410 - accuracy: 0.5076 - val_loss: 0.2408 - val_accuracy: 0.5088\n",
      "Epoch 31/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2394 - accuracy: 0.5076 - val_loss: 0.2391 - val_accuracy: 0.5088\n",
      "Epoch 32/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2375 - accuracy: 0.5076 - val_loss: 0.2371 - val_accuracy: 0.5088\n",
      "Epoch 33/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2353 - accuracy: 0.5595 - val_loss: 0.2349 - val_accuracy: 0.8336\n",
      "Epoch 34/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2329 - accuracy: 0.8249 - val_loss: 0.2324 - val_accuracy: 0.8192\n",
      "Epoch 35/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2303 - accuracy: 0.8116 - val_loss: 0.2298 - val_accuracy: 0.8040\n",
      "Epoch 36/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2277 - accuracy: 0.7955 - val_loss: 0.2272 - val_accuracy: 0.7864\n",
      "Epoch 37/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2251 - accuracy: 0.7728 - val_loss: 0.2247 - val_accuracy: 0.7756\n",
      "Epoch 38/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2225 - accuracy: 0.7652 - val_loss: 0.2221 - val_accuracy: 0.7644\n",
      "Epoch 39/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2198 - accuracy: 0.7601 - val_loss: 0.2194 - val_accuracy: 0.7568\n",
      "Epoch 40/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2171 - accuracy: 0.7572 - val_loss: 0.2166 - val_accuracy: 0.7560\n",
      "Epoch 41/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2142 - accuracy: 0.7584 - val_loss: 0.2138 - val_accuracy: 0.7600\n",
      "Epoch 42/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2112 - accuracy: 0.7623 - val_loss: 0.2107 - val_accuracy: 0.7628\n",
      "Epoch 43/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2080 - accuracy: 0.7669 - val_loss: 0.2076 - val_accuracy: 0.7680\n",
      "Epoch 44/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2047 - accuracy: 0.7751 - val_loss: 0.2043 - val_accuracy: 0.7756\n",
      "Epoch 45/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2013 - accuracy: 0.7781 - val_loss: 0.2009 - val_accuracy: 0.7832\n",
      "Epoch 46/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.1978 - accuracy: 0.7864 - val_loss: 0.1974 - val_accuracy: 0.7924\n",
      "Epoch 47/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.1941 - accuracy: 0.7931 - val_loss: 0.1938 - val_accuracy: 0.8008\n",
      "Epoch 48/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.1904 - accuracy: 0.8012 - val_loss: 0.1900 - val_accuracy: 0.8128\n",
      "Epoch 49/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.1865 - accuracy: 0.8167 - val_loss: 0.1862 - val_accuracy: 0.8224\n",
      "Epoch 50/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.1826 - accuracy: 0.8223 - val_loss: 0.1823 - val_accuracy: 0.8320\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(2, activation='relu', input_shape=[2]))\n",
    "model.add(keras.layers.Dense(2, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='mse',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(x_new, y_new, validation_split=0.25, epochs=50, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    }
   ],
   "source": [
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.legend.Legend at 0x27ddcfaafd0>"
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['Train', 'Val'], loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.legend.Legend at 0x27dde127a00>"
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('acc')\n",
    "plt.legend(['Train', 'Val'], loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Correct loss function\n",
    "\n",
    "The loss function used above (mse) is not optimal. A better loss function would be the crossentropy. Change the network to use that loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'keras' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [1], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mkeras\u001B[49m\u001B[38;5;241m.\u001B[39mSequential()\n\u001B[0;32m      2\u001B[0m model\u001B[38;5;241m.\u001B[39madd(keras\u001B[38;5;241m.\u001B[39mlayers\u001B[38;5;241m.\u001B[39mDense(\u001B[38;5;241m2\u001B[39m, activation\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrelu\u001B[39m\u001B[38;5;124m'\u001B[39m, input_shape\u001B[38;5;241m=\u001B[39m[\u001B[38;5;241m2\u001B[39m]))\n\u001B[0;32m      3\u001B[0m model\u001B[38;5;241m.\u001B[39madd(keras\u001B[38;5;241m.\u001B[39mlayers\u001B[38;5;241m.\u001B[39mDense(\u001B[38;5;241m2\u001B[39m, activation\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrelu\u001B[39m\u001B[38;5;124m'\u001B[39m))\n",
      "\u001B[1;31mNameError\u001B[0m: name 'keras' is not defined"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(2, activation='relu', input_shape=[2]))\n",
    "model.add(keras.layers.Dense(2, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='mean_absolute_error',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(x_new, y_new, validation_split=0.25, epochs=50, batch_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Maximum of 4 colors\n",
    "\n",
    "Implement a network that will receive 4 colors and has to select one of them.\n",
    "\n",
    "This will require a change of the labels (y) that now take values of 0, 1, 2 or 3. However, networks do not use labels in that form directly for multi class classification, but use 1-hot encoded or categorical data instead.\n",
    "\n",
    "In keras there is a function `keras.utils.to_categorical` that can be used for that.\n",
    "\n",
    "The last layer in the network should then no longer be sigmoid, but the softmax function. And we need the multiclass form of the crossentropy function, which in keras is called `categorical_crossentropy`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.random.random(size=(5000, 4))\n",
    "y_train_label = np.argmax(x_train, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Implement a ML Network to learn trump from features\n",
    "\n",
    "We would like to train a network to get the trump from some features. (We could use the cards directly, but this is deep learning and we will see more of that in next lesson :-) )\n",
    "\n",
    "As features we can use the number of cards of a color as before and some of the features from last lecture. For keras all input features should be floating point numbers. Also we need numpy arrays and not pandas. To get the array from a panda, the property `values` can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   DA  DK  DQ  DJ  D10  D9  D8  D7  D6  HA  ...  CK  CQ  CJ  C10  C9  C8  C7  \\\n",
      "0   0   0   0   1    1   0   1   1   0   0  ...   0   1   0    0   0   1   0   \n",
      "1   0   0   0   0    0   0   0   0   1   1  ...   0   0   1    0   0   0   1   \n",
      "2   1   0   0   1    0   0   0   0   0   0  ...   0   1   0    0   0   0   1   \n",
      "3   0   0   0   0    0   0   0   0   0   1  ...   0   0   0    1   1   0   0   \n",
      "4   0   1   0   0    0   0   0   0   1   1  ...   0   0   1    0   0   0   0   \n",
      "\n",
      "   C6  FH  trump  \n",
      "0   0   0      6  \n",
      "1   0   0      5  \n",
      "2   1   0      6  \n",
      "3   0   0      5  \n",
      "4   0   1      4  \n",
      "\n",
      "[5 rows x 38 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "path_to_data = Path('../ml/')\n",
    "# Import only a fraction of data for efficient testing\n",
    "data = pd.read_csv(path_to_data / '2018_10_18_trump.csv', header=None)\n",
    "cards = [\n",
    "    # Diamonds\n",
    "    'DA', 'DK', 'DQ', 'DJ', 'D10', 'D9', 'D8', 'D7', 'D6',\n",
    "    # Hearts\n",
    "    'HA', 'HK', 'HQ', 'HJ', 'H10', 'H9', 'H8', 'H7', 'H6',\n",
    "    # Spades\n",
    "    'SA', 'SK', 'SQ', 'SJ', 'S10', 'S9', 'S8', 'S7', 'S6',\n",
    "    # Clubs\n",
    "    'CA', 'CK', 'CQ', 'CJ', 'C10', 'C9', 'C8', 'C7', 'C6'\n",
    "]\n",
    "\n",
    "# Forehand (yes = 1, no = 0)\n",
    "forehand = ['FH']\n",
    "\n",
    "user = ['user']\n",
    "trump = ['trump']\n",
    "\n",
    "data.columns = cards + forehand + user + trump\n",
    "feature_columns = cards + forehand\n",
    "data.drop('user', axis='columns', inplace=True)\n",
    "# data.trump = data.trump.astype('category')\n",
    "\n",
    "# data.shape\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   DA  DK  DQ  DJ  D10  D9  D8  D7  D6  HA  ...  C8  C7  C6  FH  D  H  S  C  \\\n",
      "0   0   0   0   1    1   0   1   1   0   0  ...   1   0   0   0  0  0  0  0   \n",
      "1   0   0   0   0    0   0   0   0   1   1  ...   0   1   0   0  0  0  0  0   \n",
      "2   1   0   0   1    0   0   0   0   0   0  ...   0   1   1   0  0  0  0  0   \n",
      "3   0   0   0   0    0   0   0   0   0   1  ...   0   0   0   0  0  0  0  0   \n",
      "4   0   1   0   0    0   0   0   0   1   1  ...   0   0   0   1  0  0  0  1   \n",
      "\n",
      "   O  U  \n",
      "0  0  1  \n",
      "1  1  0  \n",
      "2  0  1  \n",
      "3  1  0  \n",
      "4  0  0  \n",
      "\n",
      "[5 rows x 43 columns]\n"
     ]
    }
   ],
   "source": [
    "dummy1 = pd.get_dummies(data['trump'], drop_first=True)\n",
    "dummy1.head()\n",
    "trumps = ['D', 'H', 'S', 'C', 'O', 'U']\n",
    "dummy1.columns = trumps\n",
    "dummy1.head()\n",
    "data = pd.concat([data, dummy1], axis=1).drop('trump', axis=1)\n",
    "print(data.head())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   DA  DK  DQ  DJ  D10  D9  D8  D7  D6  HA  ...  D_678  H_J9  H_AKQ  H_678  \\\n",
      "0   0   0   0   1    1   0   1   1   0   0  ...      0     0      0      0   \n",
      "1   0   0   0   0    0   0   0   0   1   1  ...      0     0      0      0   \n",
      "2   1   0   0   1    0   0   0   0   0   0  ...      0     0      0      0   \n",
      "3   0   0   0   0    0   0   0   0   0   1  ...      0     0      0      0   \n",
      "4   0   1   0   0    0   0   0   0   1   1  ...      0     0      1      0   \n",
      "\n",
      "   S_J9  S_AKQ  S_678  C_J9  C_AKQ  C_678  \n",
      "0     0      0      0     0      0      0  \n",
      "1     0      0      0     0      0      0  \n",
      "2     0      0      0     0      0      0  \n",
      "3     0      0      0     0      0      0  \n",
      "4     0      0      0     0      0      0  \n",
      "\n",
      "[5 rows x 55 columns]\n"
     ]
    }
   ],
   "source": [
    "for color in 'DHSC':\n",
    "    # Jack and nine combination\n",
    "    new_col = '{}_J9'.format(color)\n",
    "    data[new_col] = data['{}J'.format(color)] & data['{}9'.format(color)]\n",
    "    feature_columns.append(new_col)\n",
    "\n",
    "    new_col = '{}_AKQ'.format(color)\n",
    "    data[new_col] = data['{}A'.format(color)] & data['{}K'.format(color)] & data['{}Q'.format(color)]\n",
    "    feature_columns.append(new_col)\n",
    "\n",
    "    new_col = '{}_678'.format(color)\n",
    "    data[new_col] = data['{}6'.format(color)] & data['{}7'.format(color)] & data['{}8'.format(color)]\n",
    "    feature_columns.append(new_col)\n",
    "\n",
    "print(data.head())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continue as follows:\n",
    "- Calculate features, \n",
    "- add them to the data set\n",
    "- drop the columns not used\n",
    "- convert to numpy array\n",
    "- build a network and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(287860, 49)\n",
      "        DA  DK  DQ  DJ  D10  D9  D8  D7  D6  HA  ...  D_678  H_J9  H_AKQ  \\\n",
      "311259   1   0   0   0    1   0   0   0   0   1  ...      0     0      0   \n",
      "79927    0   0   1   0    0   1   0   1   1   0  ...      0     0      0   \n",
      "133742   1   0   1   1    0   0   0   0   0   0  ...      0     0      0   \n",
      "338250   0   1   0   0    0   1   1   0   0   0  ...      0     0      0   \n",
      "65075    0   0   0   0    0   1   0   0   0   0  ...      0     0      0   \n",
      "\n",
      "        H_678  S_J9  S_AKQ  S_678  C_J9  C_AKQ  C_678  \n",
      "311259      0     0      0      0     0      0      0  \n",
      "79927       0     0      0      0     0      0      0  \n",
      "133742      0     0      0      0     1      0      0  \n",
      "338250      0     0      0      0     0      0      0  \n",
      "65075       0     0      0      0     1      0      0  \n",
      "\n",
      "[5 rows x 49 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[feature_columns], data[trumps], test_size=0.2,\n",
    "                                                    stratify=data[trumps], random_state=42, shuffle=True)\n",
    "print(X_train.shape)\n",
    "print(X_train.head())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2249/2249 [==============================] - 5s 2ms/step - loss: 0.7653 - accuracy: 0.6160\n",
      "Epoch 2/10\n",
      "2249/2249 [==============================] - 5s 2ms/step - loss: 0.7585 - accuracy: 0.6183\n",
      "Epoch 3/10\n",
      "2249/2249 [==============================] - 6s 2ms/step - loss: 0.7625 - accuracy: 0.6187\n",
      "Epoch 4/10\n",
      "2249/2249 [==============================] - 5s 2ms/step - loss: 0.7647 - accuracy: 0.6183\n",
      "Epoch 5/10\n",
      "2249/2249 [==============================] - 5s 2ms/step - loss: 0.7673 - accuracy: 0.6188\n",
      "Epoch 6/10\n",
      "2249/2249 [==============================] - 5s 2ms/step - loss: 0.7694 - accuracy: 0.6181\n",
      "Epoch 7/10\n",
      "2249/2249 [==============================] - 5s 2ms/step - loss: 0.7740 - accuracy: 0.6188\n",
      "Epoch 8/10\n",
      "2249/2249 [==============================] - 5s 2ms/step - loss: 0.7776 - accuracy: 0.6182\n",
      "Epoch 9/10\n",
      "2249/2249 [==============================] - 5s 2ms/step - loss: 0.7767 - accuracy: 0.6187\n",
      "Epoch 10/10\n",
      "2249/2249 [==============================] - 5s 2ms/step - loss: 0.7805 - accuracy: 0.6180\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2249/2249 [==============================] - 2s 890us/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multilabel-indicator and continuous-multioutput targets",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [150], line 29\u001B[0m\n\u001B[0;32m     27\u001B[0m plot_costs(history\u001B[38;5;241m.\u001B[39mhistory[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mloss\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[0;32m     28\u001B[0m y_pred \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mpredict(X_test)\n\u001B[1;32m---> 29\u001B[0m accuracy \u001B[38;5;241m=\u001B[39m \u001B[43maccuracy_score\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     30\u001B[0m \u001B[38;5;66;03m# f1 = f1_score(y_test, y_pred)\u001B[39;00m\n\u001B[0;32m     32\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAccuracy: \u001B[39m\u001B[38;5;132;01m%.4f\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m accuracy)\n",
      "File \u001B[1;32m~\\.virtualenvs\\DL4G-xN77NjMz\\lib\\site-packages\\sklearn\\metrics\\_classification.py:211\u001B[0m, in \u001B[0;36maccuracy_score\u001B[1;34m(y_true, y_pred, normalize, sample_weight)\u001B[0m\n\u001B[0;32m    145\u001B[0m \u001B[38;5;124;03m\"\"\"Accuracy classification score.\u001B[39;00m\n\u001B[0;32m    146\u001B[0m \n\u001B[0;32m    147\u001B[0m \u001B[38;5;124;03mIn multilabel classification, this function computes subset accuracy:\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    207\u001B[0m \u001B[38;5;124;03m0.5\u001B[39;00m\n\u001B[0;32m    208\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    210\u001B[0m \u001B[38;5;66;03m# Compute accuracy for each possible representation\u001B[39;00m\n\u001B[1;32m--> 211\u001B[0m y_type, y_true, y_pred \u001B[38;5;241m=\u001B[39m \u001B[43m_check_targets\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    212\u001B[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001B[0;32m    213\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m y_type\u001B[38;5;241m.\u001B[39mstartswith(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmultilabel\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
      "File \u001B[1;32m~\\.virtualenvs\\DL4G-xN77NjMz\\lib\\site-packages\\sklearn\\metrics\\_classification.py:93\u001B[0m, in \u001B[0;36m_check_targets\u001B[1;34m(y_true, y_pred)\u001B[0m\n\u001B[0;32m     90\u001B[0m     y_type \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmulticlass\u001B[39m\u001B[38;5;124m\"\u001B[39m}\n\u001B[0;32m     92\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(y_type) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m---> 93\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m     94\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mClassification metrics can\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt handle a mix of \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m and \u001B[39m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;124m targets\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[0;32m     95\u001B[0m             type_true, type_pred\n\u001B[0;32m     96\u001B[0m         )\n\u001B[0;32m     97\u001B[0m     )\n\u001B[0;32m     99\u001B[0m \u001B[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001B[39;00m\n\u001B[0;32m    100\u001B[0m y_type \u001B[38;5;241m=\u001B[39m y_type\u001B[38;5;241m.\u001B[39mpop()\n",
      "\u001B[1;31mValueError\u001B[0m: Classification metrics can't handle a mix of multilabel-indicator and continuous-multioutput targets"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model = keras.Sequential()\n",
    "dataset_dim = X_train.shape[1]\n",
    "\n",
    "model.add(keras.layers.Dense(49, activation=keras.activations.tanh, input_shape=(dataset_dim,)))\n",
    "model.add(keras.layers.Dense(300, activation=keras.activations.tanh))\n",
    "model.add(keras.layers.Dense(200, activation=keras.activations.tanh))\n",
    "# model.add(keras.layers.Dense(200, activation=keras.activations.sigmo id))\n",
    "# model.add(keras.layers.Dense(100, activation=keras.activations.sigmoid))\n",
    "model.add(keras.layers.Dense(6, activation=keras.activations.softmax))\n",
    "model.compile(loss=keras.losses.CategoricalCrossentropy(),\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=128)\n",
    "\n",
    "\n",
    "def plot_costs(costs):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(costs)\n",
    "    ax.set_title(\"Loss curve\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_costs(history.history[\"loss\"])\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "# f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy: %.4f\" % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2249/2249 [==============================] - 2s 912us/step\n",
      "563/563 [==============================] - 1s 1ms/step - loss: 0.8032 - accuracy: 0.6128\n",
      "test loss, test acc: [0.8031876683235168, 0.6127700805664062]\n",
      "[[8.69500339e-02 4.03172299e-02 4.21593599e-02 1.15867004e-01\n",
      "  7.98678026e-02 6.34838581e-01]\n",
      " [1.35023452e-04 6.83764592e-05 8.20504222e-03 2.18304322e-05\n",
      "  9.91342783e-01 2.26895922e-04]\n",
      " [1.16366655e-05 4.58189892e-03 1.02515071e-06 3.21878724e-06\n",
      "  9.92438793e-01 2.96335644e-03]\n",
      " ...\n",
      " [1.72740538e-02 7.33933784e-03 3.91145170e-01 1.65920295e-02\n",
      "  2.02052798e-02 5.47444105e-01]\n",
      " [2.86147883e-06 7.24634575e-03 1.11947747e-06 5.75867052e-05\n",
      "  9.92690742e-01 1.32568505e-06]\n",
      " [9.00015384e-02 4.23376337e-02 4.40026820e-02 8.83469954e-02\n",
      "  9.52929482e-02 6.40018284e-01]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "result = model.evaluate(X_test, y_test, batch_size=128)\n",
    "print(\"test loss, test acc:\", result)\n",
    "print(y_pred)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: mlp_model_v2\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"mlp_model_v2\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
