{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example for a simple neural network\n",
    "\n",
    "## Trump by maximum color (2 colors)\n",
    "\n",
    "The inputs to the network are the number of cards of each color. The network should learn to select the color with the largest number of cards of that color.\n",
    "\n",
    "For a simple example, let us assume that there are 5 cards in total for a player and only 2 colors.\n",
    "\n",
    "### Libraries\n",
    "\n",
    "We use the keras library for building, training and evaluating the network. A tutorial for keras can be found on (https://keras.io/) or https://www.tensorflow.org/guide/keras. There are different implementations of keras, here I will use the one build on tensorflow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output function\n",
    "\n",
    "We have to encode the output somehow, for two classes, the simplest solution is a single variable that should be 0 if there are more cards of color 0 and 1 if there are more cards of color 1.\n",
    "\n",
    "### Training and label data.\n",
    "\n",
    "So we can prepare some training data. In this simple case, all the possible configurations are actually known.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 5.]\n",
      " [1. 4.]\n",
      " [2. 3.]\n",
      " [3. 2.]\n",
      " [4. 1.]\n",
      " [5. 0.]]\n",
      "[1. 1. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "x_train = np.array([\n",
    "    [0, 5],\n",
    "    [1, 4],\n",
    "    [2, 3],\n",
    "    [3, 2],\n",
    "    [4, 1],\n",
    "    [5, 0],\n",
    "], dtype=np.float32)\n",
    "y_train = np.array([1, 1, 1, 0, 0, 0, ], dtype=np.float32)\n",
    "print(x_train)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalisation\n",
    "\n",
    "Input data can have different ranges. It is always a good idea (in other words absolutely essential) to normalize the input data. This is usually done into the range 0..1 or -1..1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.  1. ]\n",
      " [0.2 0.8]\n",
      " [0.4 0.6]\n",
      " [0.6 0.4]\n",
      " [0.8 0.2]\n",
      " [1.  0. ]]\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train / 5.0\n",
    "print(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A first network.\n",
    "\n",
    "We will start with a very simple network, where we connect the inputs directly to the output. So there will be 2 variables, the weights for the connection and the bias. The output function is a sigmoid, which takes values between 0 and 1.\n",
    "\n",
    "With keras, we first have to create the type of model we want (Sequential), and can then add layers. In the tensorflow implementation, we have to add the input_shape parameter in the first layer to tell it the format of the input. This does not include the batch dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid', input_shape=[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we have to compile the model and tell it what loss function and optimizer we want to have. We will take a mean squared error for loss function first. (This is actually not optimal and will be corrected in an exercise).\n",
    "\n",
    "Besides the loss, we usually want to look at some metrics. Here we choose accuracy, that measures how often the network makes the correct decision (see last lecture)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can print some details about the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_21 (Dense)            (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3\n",
      "Trainable params: 3\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "[array([[0.68495166],\n",
      "       [0.32549334]], dtype=float32), array([0.], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "print(model.get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can either train one batch, or we can use fit to train repeatedly. The result from the training is the loss function and the metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[0.2912900447845459, 0.5]"
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train_on_batch(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now try to fit the data in minibatches multiple times. This will calculate the weights, so as to minimize the loss. We might not always get a good result in the first try and even this very simple network seems to need a large number of training steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2911 - accuracy: 0.5000\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2910 - accuracy: 0.5000\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2908 - accuracy: 0.5000\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2907 - accuracy: 0.5000\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2905 - accuracy: 0.5000\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2904 - accuracy: 0.5000\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2902 - accuracy: 0.5000\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2901 - accuracy: 0.5000\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2900 - accuracy: 0.5000\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2898 - accuracy: 0.5000\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2897 - accuracy: 0.5000\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2895 - accuracy: 0.5000\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2894 - accuracy: 0.5000\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2892 - accuracy: 0.5000\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2891 - accuracy: 0.5000\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2889 - accuracy: 0.5000\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2888 - accuracy: 0.5000\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2886 - accuracy: 0.5000\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2885 - accuracy: 0.5000\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2883 - accuracy: 0.5000\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2882 - accuracy: 0.5000\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2880 - accuracy: 0.5000\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2879 - accuracy: 0.5000\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2877 - accuracy: 0.5000\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2876 - accuracy: 0.5000\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2874 - accuracy: 0.5000\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2873 - accuracy: 0.5000\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2871 - accuracy: 0.5000\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2870 - accuracy: 0.5000\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2868 - accuracy: 0.5000\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2867 - accuracy: 0.5000\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2865 - accuracy: 0.5000\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2864 - accuracy: 0.5000\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2863 - accuracy: 0.5000\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2861 - accuracy: 0.5000\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2860 - accuracy: 0.5000\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2858 - accuracy: 0.5000\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2857 - accuracy: 0.5000\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2855 - accuracy: 0.5000\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2854 - accuracy: 0.5000\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2852 - accuracy: 0.5000\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2851 - accuracy: 0.5000\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2849 - accuracy: 0.5000\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2848 - accuracy: 0.5000\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2846 - accuracy: 0.5000\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2845 - accuracy: 0.5000\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2843 - accuracy: 0.5000\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2842 - accuracy: 0.5000\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2841 - accuracy: 0.5000\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2839 - accuracy: 0.5000\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2838 - accuracy: 0.5000\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2836 - accuracy: 0.5000\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2835 - accuracy: 0.5000\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2833 - accuracy: 0.5000\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2832 - accuracy: 0.5000\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2830 - accuracy: 0.5000\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2829 - accuracy: 0.5000\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2827 - accuracy: 0.5000\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2826 - accuracy: 0.5000\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2824 - accuracy: 0.5000\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2823 - accuracy: 0.5000\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2822 - accuracy: 0.5000\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2820 - accuracy: 0.5000\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2819 - accuracy: 0.5000\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2817 - accuracy: 0.5000\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2816 - accuracy: 0.5000\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2814 - accuracy: 0.5000\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2813 - accuracy: 0.5000\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2811 - accuracy: 0.5000\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2810 - accuracy: 0.5000\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2808 - accuracy: 0.5000\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2807 - accuracy: 0.5000\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2806 - accuracy: 0.5000\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2804 - accuracy: 0.5000\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2803 - accuracy: 0.5000\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2801 - accuracy: 0.5000\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2800 - accuracy: 0.5000\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2798 - accuracy: 0.5000\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2797 - accuracy: 0.5000\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2795 - accuracy: 0.5000\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2794 - accuracy: 0.5000\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2793 - accuracy: 0.5000\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2791 - accuracy: 0.5000\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2790 - accuracy: 0.5000\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2788 - accuracy: 0.5000\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2787 - accuracy: 0.5000\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2785 - accuracy: 0.5000\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2784 - accuracy: 0.5000\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2782 - accuracy: 0.5000\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2781 - accuracy: 0.5000\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2780 - accuracy: 0.5000\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2778 - accuracy: 0.5000\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2777 - accuracy: 0.5000\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2775 - accuracy: 0.5000\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2774 - accuracy: 0.5000\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2772 - accuracy: 0.5000\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2771 - accuracy: 0.5000\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2770 - accuracy: 0.5000\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2768 - accuracy: 0.5000\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2767 - accuracy: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x27ddce47f40>"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=100, batch_size=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can predict the values from the training value. Why are the results floating point number and not 0 or 1? Does the result seem likely?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 36ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[0.58072937],\n       [0.59090716],\n       [0.6010077 ],\n       [0.61102295],\n       [0.6209454 ],\n       [0.63076764]], dtype=float32)"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also print the found weights for each layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense_21\n",
      "[array([[0.58523333],\n",
      "       [0.37549004]], dtype=float32), array([-0.04972177], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    weights = layer.get_weights()\n",
    "    print(layer.name)\n",
    "    print(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we find the actual predictions? We use a threshold on the output of the sigmoid function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[ True],\n       [ True],\n       [ True],\n       [ True],\n       [ True],\n       [ True]])"
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_train) > 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A larger network\n",
    "\n",
    "Lets try a more complicated network with two hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(2, activation='relu', input_shape=[2]))  # hidden\n",
    "model.add(keras.layers.Dense(2, activation='relu'))  # hidden\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))  # output\n",
    "model.compile(loss='mse',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And train it again..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.3020 - accuracy: 0.1667\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3015 - accuracy: 0.1667\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3009 - accuracy: 0.1667\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3004 - accuracy: 0.1667\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2999 - accuracy: 0.1667\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2994 - accuracy: 0.1667\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2989 - accuracy: 0.1667\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2984 - accuracy: 0.1667\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2979 - accuracy: 0.1667\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2974 - accuracy: 0.1667\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2968 - accuracy: 0.1667\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2963 - accuracy: 0.1667\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2958 - accuracy: 0.1667\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2953 - accuracy: 0.1667\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2949 - accuracy: 0.1667\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2944 - accuracy: 0.1667\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2939 - accuracy: 0.1667\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2934 - accuracy: 0.1667\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2929 - accuracy: 0.1667\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2924 - accuracy: 0.1667\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2919 - accuracy: 0.1667\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2914 - accuracy: 0.1667\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2910 - accuracy: 0.1667\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2905 - accuracy: 0.1667\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2900 - accuracy: 0.1667\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2895 - accuracy: 0.1667\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2890 - accuracy: 0.1667\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2886 - accuracy: 0.1667\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2881 - accuracy: 0.1667\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2876 - accuracy: 0.1667\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2872 - accuracy: 0.1667\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2867 - accuracy: 0.1667\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2863 - accuracy: 0.1667\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2858 - accuracy: 0.1667\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2853 - accuracy: 0.1667\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2849 - accuracy: 0.1667\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2844 - accuracy: 0.1667\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2840 - accuracy: 0.1667\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2835 - accuracy: 0.1667\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2831 - accuracy: 0.1667\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2827 - accuracy: 0.1667\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2823 - accuracy: 0.1667\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2819 - accuracy: 0.1667\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2815 - accuracy: 0.1667\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2812 - accuracy: 0.1667\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2808 - accuracy: 0.1667\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2804 - accuracy: 0.1667\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2800 - accuracy: 0.1667\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2796 - accuracy: 0.1667\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2793 - accuracy: 0.1667\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2789 - accuracy: 0.1667\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2785 - accuracy: 0.1667\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2782 - accuracy: 0.1667\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2778 - accuracy: 0.1667\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2774 - accuracy: 0.1667\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2771 - accuracy: 0.1667\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2767 - accuracy: 0.1667\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2763 - accuracy: 0.1667\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2760 - accuracy: 0.1667\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2756 - accuracy: 0.1667\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2753 - accuracy: 0.1667\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2749 - accuracy: 0.1667\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2745 - accuracy: 0.1667\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2742 - accuracy: 0.1667\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2738 - accuracy: 0.1667\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2735 - accuracy: 0.1667\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2731 - accuracy: 0.1667\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2728 - accuracy: 0.1667\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2724 - accuracy: 0.1667\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2721 - accuracy: 0.1667\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2717 - accuracy: 0.1667\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2714 - accuracy: 0.1667\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2711 - accuracy: 0.1667\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2707 - accuracy: 0.1667\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2704 - accuracy: 0.1667\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2700 - accuracy: 0.1667\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2697 - accuracy: 0.1667\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2694 - accuracy: 0.1667\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2690 - accuracy: 0.1667\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2687 - accuracy: 0.1667\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2684 - accuracy: 0.1667\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2681 - accuracy: 0.1667\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2677 - accuracy: 0.1667\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2674 - accuracy: 0.1667\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2671 - accuracy: 0.1667\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2668 - accuracy: 0.1667\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2664 - accuracy: 0.1667\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2661 - accuracy: 0.1667\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2658 - accuracy: 0.1667\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2655 - accuracy: 0.1667\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2652 - accuracy: 0.3333\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2648 - accuracy: 0.3333\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2645 - accuracy: 0.3333\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2643 - accuracy: 0.3333\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2641 - accuracy: 0.3333\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2640 - accuracy: 0.3333\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2639 - accuracy: 0.3333\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2638 - accuracy: 0.3333\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2637 - accuracy: 0.3333\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2636 - accuracy: 0.3333\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2635 - accuracy: 0.3333\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2634 - accuracy: 0.3333\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2633 - accuracy: 0.3333\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2632 - accuracy: 0.3333\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2632 - accuracy: 0.3333\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2631 - accuracy: 0.3333\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2630 - accuracy: 0.3333\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2629 - accuracy: 0.3333\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2628 - accuracy: 0.3333\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2627 - accuracy: 0.3333\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2626 - accuracy: 0.3333\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2625 - accuracy: 0.3333\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2625 - accuracy: 0.3333\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2624 - accuracy: 0.3333\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2623 - accuracy: 0.3333\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2622 - accuracy: 0.3333\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2621 - accuracy: 0.3333\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2620 - accuracy: 0.3333\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2619 - accuracy: 0.3333\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2618 - accuracy: 0.3333\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2618 - accuracy: 0.3333\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2617 - accuracy: 0.3333\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2616 - accuracy: 0.3333\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2615 - accuracy: 0.3333\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2614 - accuracy: 0.3333\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2613 - accuracy: 0.3333\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2613 - accuracy: 0.3333\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2612 - accuracy: 0.3333\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2611 - accuracy: 0.3333\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2610 - accuracy: 0.3333\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2609 - accuracy: 0.3333\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2608 - accuracy: 0.3333\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2608 - accuracy: 0.3333\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2607 - accuracy: 0.3333\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2606 - accuracy: 0.3333\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2605 - accuracy: 0.3333\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2604 - accuracy: 0.3333\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2603 - accuracy: 0.3333\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2603 - accuracy: 0.3333\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2602 - accuracy: 0.3333\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2601 - accuracy: 0.3333\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2600 - accuracy: 0.3333\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2599 - accuracy: 0.3333\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2599 - accuracy: 0.3333\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2598 - accuracy: 0.3333\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2597 - accuracy: 0.3333\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2596 - accuracy: 0.3333\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2595 - accuracy: 0.3333\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2594 - accuracy: 0.3333\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2594 - accuracy: 0.3333\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2593 - accuracy: 0.3333\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2592 - accuracy: 0.3333\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2591 - accuracy: 0.3333\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2591 - accuracy: 0.3333\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2590 - accuracy: 0.3333\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2589 - accuracy: 0.3333\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2588 - accuracy: 0.3333\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2587 - accuracy: 0.3333\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2587 - accuracy: 0.3333\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.2586 - accuracy: 0.3333\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2585 - accuracy: 0.3333\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2584 - accuracy: 0.3333\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2583 - accuracy: 0.3333\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2583 - accuracy: 0.3333\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2582 - accuracy: 0.3333\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2581 - accuracy: 0.3333\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2580 - accuracy: 0.3333\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2580 - accuracy: 0.3333\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2579 - accuracy: 0.3333\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2578 - accuracy: 0.3333\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2577 - accuracy: 0.3333\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2577 - accuracy: 0.3333\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2576 - accuracy: 0.3333\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2575 - accuracy: 0.3333\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2574 - accuracy: 0.3333\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2574 - accuracy: 0.3333\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2573 - accuracy: 0.3333\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2572 - accuracy: 0.3333\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2571 - accuracy: 0.3333\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2571 - accuracy: 0.3333\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2570 - accuracy: 0.3333\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2569 - accuracy: 0.3333\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2568 - accuracy: 0.3333\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2568 - accuracy: 0.3333\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2567 - accuracy: 0.3333\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2566 - accuracy: 0.3333\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2565 - accuracy: 0.3333\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2565 - accuracy: 0.3333\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2564 - accuracy: 0.3333\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2563 - accuracy: 0.3333\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2562 - accuracy: 0.3333\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2562 - accuracy: 0.3333\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2561 - accuracy: 0.3333\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2560 - accuracy: 0.3333\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2559 - accuracy: 0.3333\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2559 - accuracy: 0.3333\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2558 - accuracy: 0.3333\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2557 - accuracy: 0.3333\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2557 - accuracy: 0.3333\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2556 - accuracy: 0.3333\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x27ddcea88b0>"
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=200, batch_size=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are not necessarly better, how does the prediction look now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000027DDCEDD040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 44ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[0.49708238],\n       [0.49708238],\n       [0.49708238],\n       [0.49708238],\n       [0.49708238],\n       [0.5292833 ]], dtype=float32)"
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.layers.core.dense.Dense object at 0x0000027DDCEA8A00>\n",
      "[array([[ 0.6028108, -0.965752 ],\n",
      "       [-1.191112 , -0.1566987]], dtype=float32), array([-0.12573428,  0.        ], dtype=float32)]\n",
      "<keras.layers.core.dense.Dense object at 0x0000027DDCEA82B0>\n",
      "[array([[ 0.09312582,  0.5909856 ],\n",
      "       [ 0.77801263, -0.3098777 ]], dtype=float32), array([-0.05180462, -0.18868946], dtype=float32)]\n",
      "<keras.layers.core.dense.Dense object at 0x0000027DDC1B4AC0>\n",
      "[array([[0.7886322],\n",
      "       [1.3826257]], dtype=float32), array([-0.01167064], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    weights = layer.get_weights()\n",
    "    print(layer)\n",
    "    print(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The larger network, does not seem to work better as the simpler one. Or is it maybe not large enough?\n",
    "\n",
    "The problem is not the network, but the data, we just do not have enough data. So lets try to make up some more data artificially.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_new = np.random.random(size=(10000, 2))\n",
    "y_new = np.zeros(10000, dtype=np.float32)\n",
    "condition = (x_new[:, 1] > x_new[:, 0])\n",
    "y_new[condition] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 976us/step - loss: 0.2501 - accuracy: 0.4961\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 861us/step - loss: 0.2501 - accuracy: 0.4996\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 819us/step - loss: 0.2500 - accuracy: 0.5013\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 823us/step - loss: 0.2500 - accuracy: 0.5023\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 844us/step - loss: 0.2500 - accuracy: 0.5033\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 798us/step - loss: 0.2500 - accuracy: 0.5045\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 801us/step - loss: 0.2500 - accuracy: 0.5049\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 759us/step - loss: 0.2500 - accuracy: 0.5056\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 804us/step - loss: 0.2500 - accuracy: 0.5062\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 763us/step - loss: 0.2500 - accuracy: 0.5067\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 788us/step - loss: 0.2500 - accuracy: 0.5073\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 752us/step - loss: 0.2500 - accuracy: 0.5074\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 753us/step - loss: 0.2500 - accuracy: 0.5076\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 774us/step - loss: 0.2499 - accuracy: 0.5077\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 883us/step - loss: 0.2499 - accuracy: 0.5077\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 809us/step - loss: 0.2499 - accuracy: 0.5077\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 758us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 733us/step - loss: 0.2499 - accuracy: 0.5078\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 773us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 788us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 778us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 788us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 914us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 942us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 960us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 890us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 864us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 753us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 834us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 788us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 753us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 750us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 753us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 743us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 778us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 773us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 773us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 792us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 727us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 768us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 758us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 763us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 763us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 758us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 732us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 732us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 738us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 768us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 748us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 748us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 751us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 844us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 823us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 828us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 803us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 753us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 768us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 737us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 740us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 788us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 724us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 837us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 758us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 773us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 762us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 975us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 990us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 920us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 910us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 904us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 975us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 879us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 854us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 808us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 793us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 788us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 783us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 813us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - 0s 849us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - 0s 859us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - 0s 813us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - 0s 783us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - 0s 758us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - 0s 748us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - 0s 737us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - 0s 799us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - 0s 753us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - 0s 753us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - 0s 743us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 90/100\n",
      "100/100 [==============================] - 0s 758us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 91/100\n",
      "100/100 [==============================] - 0s 763us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 92/100\n",
      "100/100 [==============================] - 0s 758us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 93/100\n",
      "100/100 [==============================] - 0s 823us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 94/100\n",
      "100/100 [==============================] - 0s 763us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 95/100\n",
      "100/100 [==============================] - 0s 747us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 96/100\n",
      "100/100 [==============================] - 0s 770us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 97/100\n",
      "100/100 [==============================] - 0s 768us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 98/100\n",
      "100/100 [==============================] - 0s 788us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 99/100\n",
      "100/100 [==============================] - 0s 768us/step - loss: 0.2499 - accuracy: 0.5079\n",
      "Epoch 100/100\n",
      "100/100 [==============================] - 0s 768us/step - loss: 0.2499 - accuracy: 0.5079\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x27ddcf5a040>"
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_new, y_new, epochs=100, batch_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That seems better. Lets look how it performs on our original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[0.49201426],\n       [0.49201426],\n       [0.49201426],\n       [0.49201426],\n       [0.49201426],\n       [0.49572238]], dtype=float32)"
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "We might want to check how the network performs on any data. For this, keras provides the evaluate function that will \n",
    "evaluate the loss and the metrics. So of course label (y) data is needed for that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 667us/step - loss: 0.2499 - accuracy: 0.5079\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.24993766844272614, 0.5078999996185303]"
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_new, y_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, we would normally do that on validation or test data not used during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 751us/step - loss: 0.2501 - accuracy: 0.4996\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.250071257352829, 0.49959999322891235]"
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val_new = np.random.random(size=(5000, 2))\n",
    "y_val_new = np.zeros(5000, dtype=np.float32)\n",
    "y_val_new[x_val_new[:, 1] > x_val_new[:, 0]] = 1.0\n",
    "model.evaluate(x_val_new, y_val_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation\n",
    "\n",
    "It is essential to visualise the training process to see what is going on. In Keras, an easy method to do this is to use the history object that is returned from fit. It contains the metrics and the loss.\n",
    "\n",
    "We will also split our data into training and validation for this test. We rebuild the model, so that it is initialized again. Otherwise we would just continue with the weights from the previous fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.2497 - accuracy: 0.5075 - val_loss: 0.2497 - val_accuracy: 0.5088\n",
      "Epoch 2/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2497 - accuracy: 0.5076 - val_loss: 0.2497 - val_accuracy: 0.5088\n",
      "Epoch 3/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2497 - accuracy: 0.5076 - val_loss: 0.2497 - val_accuracy: 0.5088\n",
      "Epoch 4/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2496 - accuracy: 0.5076 - val_loss: 0.2496 - val_accuracy: 0.5088\n",
      "Epoch 5/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2496 - accuracy: 0.5076 - val_loss: 0.2496 - val_accuracy: 0.5088\n",
      "Epoch 6/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2496 - accuracy: 0.5076 - val_loss: 0.2496 - val_accuracy: 0.5088\n",
      "Epoch 7/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2495 - accuracy: 0.5076 - val_loss: 0.2495 - val_accuracy: 0.5088\n",
      "Epoch 8/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2495 - accuracy: 0.5076 - val_loss: 0.2495 - val_accuracy: 0.5088\n",
      "Epoch 9/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2494 - accuracy: 0.5076 - val_loss: 0.2494 - val_accuracy: 0.5088\n",
      "Epoch 10/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2493 - accuracy: 0.5076 - val_loss: 0.2493 - val_accuracy: 0.5088\n",
      "Epoch 11/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2493 - accuracy: 0.5076 - val_loss: 0.2493 - val_accuracy: 0.5088\n",
      "Epoch 12/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2492 - accuracy: 0.5076 - val_loss: 0.2492 - val_accuracy: 0.5088\n",
      "Epoch 13/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2491 - accuracy: 0.5076 - val_loss: 0.2491 - val_accuracy: 0.5088\n",
      "Epoch 14/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2490 - accuracy: 0.5076 - val_loss: 0.2490 - val_accuracy: 0.5088\n",
      "Epoch 15/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2489 - accuracy: 0.5076 - val_loss: 0.2489 - val_accuracy: 0.5088\n",
      "Epoch 16/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2487 - accuracy: 0.5076 - val_loss: 0.2487 - val_accuracy: 0.5088\n",
      "Epoch 17/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2486 - accuracy: 0.5076 - val_loss: 0.2486 - val_accuracy: 0.5088\n",
      "Epoch 18/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2484 - accuracy: 0.5076 - val_loss: 0.2484 - val_accuracy: 0.5088\n",
      "Epoch 19/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2482 - accuracy: 0.5076 - val_loss: 0.2482 - val_accuracy: 0.5088\n",
      "Epoch 20/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2479 - accuracy: 0.5076 - val_loss: 0.2479 - val_accuracy: 0.5088\n",
      "Epoch 21/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2476 - accuracy: 0.5076 - val_loss: 0.2476 - val_accuracy: 0.5088\n",
      "Epoch 22/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2473 - accuracy: 0.5076 - val_loss: 0.2473 - val_accuracy: 0.5088\n",
      "Epoch 23/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2469 - accuracy: 0.5076 - val_loss: 0.2469 - val_accuracy: 0.5088\n",
      "Epoch 24/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2464 - accuracy: 0.5076 - val_loss: 0.2464 - val_accuracy: 0.5088\n",
      "Epoch 25/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2459 - accuracy: 0.5076 - val_loss: 0.2458 - val_accuracy: 0.5088\n",
      "Epoch 26/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2452 - accuracy: 0.5076 - val_loss: 0.2452 - val_accuracy: 0.5088\n",
      "Epoch 27/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2444 - accuracy: 0.5076 - val_loss: 0.2444 - val_accuracy: 0.5088\n",
      "Epoch 28/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2435 - accuracy: 0.5076 - val_loss: 0.2434 - val_accuracy: 0.5088\n",
      "Epoch 29/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2424 - accuracy: 0.5076 - val_loss: 0.2422 - val_accuracy: 0.5088\n",
      "Epoch 30/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2410 - accuracy: 0.5076 - val_loss: 0.2408 - val_accuracy: 0.5088\n",
      "Epoch 31/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2394 - accuracy: 0.5076 - val_loss: 0.2391 - val_accuracy: 0.5088\n",
      "Epoch 32/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2375 - accuracy: 0.5076 - val_loss: 0.2371 - val_accuracy: 0.5088\n",
      "Epoch 33/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2353 - accuracy: 0.5595 - val_loss: 0.2349 - val_accuracy: 0.8336\n",
      "Epoch 34/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2329 - accuracy: 0.8249 - val_loss: 0.2324 - val_accuracy: 0.8192\n",
      "Epoch 35/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2303 - accuracy: 0.8116 - val_loss: 0.2298 - val_accuracy: 0.8040\n",
      "Epoch 36/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2277 - accuracy: 0.7955 - val_loss: 0.2272 - val_accuracy: 0.7864\n",
      "Epoch 37/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2251 - accuracy: 0.7728 - val_loss: 0.2247 - val_accuracy: 0.7756\n",
      "Epoch 38/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2225 - accuracy: 0.7652 - val_loss: 0.2221 - val_accuracy: 0.7644\n",
      "Epoch 39/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2198 - accuracy: 0.7601 - val_loss: 0.2194 - val_accuracy: 0.7568\n",
      "Epoch 40/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2171 - accuracy: 0.7572 - val_loss: 0.2166 - val_accuracy: 0.7560\n",
      "Epoch 41/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2142 - accuracy: 0.7584 - val_loss: 0.2138 - val_accuracy: 0.7600\n",
      "Epoch 42/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2112 - accuracy: 0.7623 - val_loss: 0.2107 - val_accuracy: 0.7628\n",
      "Epoch 43/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2080 - accuracy: 0.7669 - val_loss: 0.2076 - val_accuracy: 0.7680\n",
      "Epoch 44/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2047 - accuracy: 0.7751 - val_loss: 0.2043 - val_accuracy: 0.7756\n",
      "Epoch 45/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2013 - accuracy: 0.7781 - val_loss: 0.2009 - val_accuracy: 0.7832\n",
      "Epoch 46/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.1978 - accuracy: 0.7864 - val_loss: 0.1974 - val_accuracy: 0.7924\n",
      "Epoch 47/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.1941 - accuracy: 0.7931 - val_loss: 0.1938 - val_accuracy: 0.8008\n",
      "Epoch 48/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.1904 - accuracy: 0.8012 - val_loss: 0.1900 - val_accuracy: 0.8128\n",
      "Epoch 49/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.1865 - accuracy: 0.8167 - val_loss: 0.1862 - val_accuracy: 0.8224\n",
      "Epoch 50/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.1826 - accuracy: 0.8223 - val_loss: 0.1823 - val_accuracy: 0.8320\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(2, activation='relu', input_shape=[2]))\n",
    "model.add(keras.layers.Dense(2, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='mse',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(x_new, y_new, validation_split=0.25, epochs=50, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    }
   ],
   "source": [
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.legend.Legend at 0x27ddcfaafd0>"
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['Train', 'Val'], loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.legend.Legend at 0x27dde127a00>"
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('acc')\n",
    "plt.legend(['Train', 'Val'], loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Correct loss function\n",
    "\n",
    "The loss function used above (mse) is not optimal. A better loss function would be the crossentropy. Change the network to use that loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'keras' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [1], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mkeras\u001B[49m\u001B[38;5;241m.\u001B[39mSequential()\n\u001B[0;32m      2\u001B[0m model\u001B[38;5;241m.\u001B[39madd(keras\u001B[38;5;241m.\u001B[39mlayers\u001B[38;5;241m.\u001B[39mDense(\u001B[38;5;241m2\u001B[39m, activation\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrelu\u001B[39m\u001B[38;5;124m'\u001B[39m, input_shape\u001B[38;5;241m=\u001B[39m[\u001B[38;5;241m2\u001B[39m]))\n\u001B[0;32m      3\u001B[0m model\u001B[38;5;241m.\u001B[39madd(keras\u001B[38;5;241m.\u001B[39mlayers\u001B[38;5;241m.\u001B[39mDense(\u001B[38;5;241m2\u001B[39m, activation\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrelu\u001B[39m\u001B[38;5;124m'\u001B[39m))\n",
      "\u001B[1;31mNameError\u001B[0m: name 'keras' is not defined"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(2, activation='relu', input_shape=[2]))\n",
    "model.add(keras.layers.Dense(2, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='mean_absolute_error',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(x_new, y_new, validation_split=0.25, epochs=50, batch_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Maximum of 4 colors\n",
    "\n",
    "Implement a network that will receive 4 colors and has to select one of them.\n",
    "\n",
    "This will require a change of the labels (y) that now take values of 0, 1, 2 or 3. However, networks do not use labels in that form directly for multi class classification, but use 1-hot encoded or categorical data instead.\n",
    "\n",
    "In keras there is a function `keras.utils.to_categorical` that can be used for that.\n",
    "\n",
    "The last layer in the network should then no longer be sigmoid, but the softmax function. And we need the multiclass form of the crossentropy function, which in keras is called `categorical_crossentropy`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.random.random(size=(5000, 4))\n",
    "y_train_label = np.argmax(x_train, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Implement a ML Network to learn trump from features\n",
    "\n",
    "We would like to train a network to get the trump from some features. (We could use the cards directly, but this is deep learning and we will see more of that in next lesson :-) )\n",
    "\n",
    "As features we can use the number of cards of a color as before and some of the features from last lecture. For keras all input features should be floating point numbers. Also we need numpy arrays and not pandas. To get the array from a panda, the property `values` can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   DA  DK  DQ  DJ  D10  D9  D8  D7  D6  HA  ...  CK  CQ  CJ  C10  C9  C8  C7  \\\n",
      "0   0   0   0   1    1   0   1   1   0   0  ...   0   1   0    0   0   1   0   \n",
      "1   0   0   0   0    0   0   0   0   1   1  ...   0   0   1    0   0   0   1   \n",
      "2   1   0   0   1    0   0   0   0   0   0  ...   0   1   0    0   0   0   1   \n",
      "3   0   0   0   0    0   0   0   0   0   1  ...   0   0   0    1   1   0   0   \n",
      "4   0   1   0   0    0   0   0   0   1   1  ...   0   0   1    0   0   0   0   \n",
      "\n",
      "   C6  FH  trump  \n",
      "0   0   0      6  \n",
      "1   0   0      5  \n",
      "2   1   0      6  \n",
      "3   0   0      5  \n",
      "4   0   1      4  \n",
      "\n",
      "[5 rows x 38 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "path_to_data = Path('../ml/')\n",
    "# Import only a fraction of data for efficient testing\n",
    "data = pd.read_csv(path_to_data / '2018_10_18_trump.csv', header=None)\n",
    "cards = [\n",
    "    # Diamonds\n",
    "    'DA', 'DK', 'DQ', 'DJ', 'D10', 'D9', 'D8', 'D7', 'D6',\n",
    "    # Hearts\n",
    "    'HA', 'HK', 'HQ', 'HJ', 'H10', 'H9', 'H8', 'H7', 'H6',\n",
    "    # Spades\n",
    "    'SA', 'SK', 'SQ', 'SJ', 'S10', 'S9', 'S8', 'S7', 'S6',\n",
    "    # Clubs\n",
    "    'CA', 'CK', 'CQ', 'CJ', 'C10', 'C9', 'C8', 'C7', 'C6'\n",
    "]\n",
    "\n",
    "# Forehand (yes = 1, no = 0)\n",
    "forehand = ['FH']\n",
    "\n",
    "user = ['user']\n",
    "trump = ['trump']\n",
    "\n",
    "data.columns = cards + forehand + user + trump\n",
    "feature_columns = cards + forehand\n",
    "data.drop('user', axis='columns', inplace=True)\n",
    "data.trump = data.trump.astype('category')\n",
    "\n",
    "# data.shape\n",
    "print(data.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[feature_columns], data.trump, test_size=0.2,\n",
    "                                                    stratify=data.trump, random_state=42)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continue as follows:\n",
    "- Calculate features, \n",
    "- add them to the data set\n",
    "- drop the columns not used\n",
    "- convert to numpy array\n",
    "- build a network and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "8996/8996 [==============================] - 8s 881us/step - loss: -44.9897 - accuracy: 0.0864\n",
      "Epoch 2/5\n",
      "8996/8996 [==============================] - 8s 880us/step - loss: -45.0343 - accuracy: 0.0864\n",
      "Epoch 3/5\n",
      "8996/8996 [==============================] - 8s 902us/step - loss: -45.0342 - accuracy: 0.0864\n",
      "Epoch 4/5\n",
      "8996/8996 [==============================] - 8s 900us/step - loss: -45.0344 - accuracy: 0.0864\n",
      "Epoch 5/5\n",
      "8996/8996 [==============================] - 8s 860us/step - loss: -45.0344 - accuracy: 0.0864\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2249/2249 [==============================] - 2s 661us/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multiclass and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [30], line 27\u001B[0m\n\u001B[0;32m     25\u001B[0m plot_costs(history\u001B[38;5;241m.\u001B[39mhistory[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mloss\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[0;32m     26\u001B[0m y_pred \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mpredict(X_test)\n\u001B[1;32m---> 27\u001B[0m accuracy \u001B[38;5;241m=\u001B[39m \u001B[43maccuracy_score\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     28\u001B[0m \u001B[38;5;66;03m# f1 = f1_score(y_test, y_pred)\u001B[39;00m\n\u001B[0;32m     30\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAccuracy: \u001B[39m\u001B[38;5;132;01m%.4f\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m accuracy)\n",
      "File \u001B[1;32m~\\.virtualenvs\\DL4G-xN77NjMz\\lib\\site-packages\\sklearn\\metrics\\_classification.py:211\u001B[0m, in \u001B[0;36maccuracy_score\u001B[1;34m(y_true, y_pred, normalize, sample_weight)\u001B[0m\n\u001B[0;32m    145\u001B[0m \u001B[38;5;124;03m\"\"\"Accuracy classification score.\u001B[39;00m\n\u001B[0;32m    146\u001B[0m \n\u001B[0;32m    147\u001B[0m \u001B[38;5;124;03mIn multilabel classification, this function computes subset accuracy:\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    207\u001B[0m \u001B[38;5;124;03m0.5\u001B[39;00m\n\u001B[0;32m    208\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    210\u001B[0m \u001B[38;5;66;03m# Compute accuracy for each possible representation\u001B[39;00m\n\u001B[1;32m--> 211\u001B[0m y_type, y_true, y_pred \u001B[38;5;241m=\u001B[39m \u001B[43m_check_targets\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    212\u001B[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001B[0;32m    213\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m y_type\u001B[38;5;241m.\u001B[39mstartswith(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmultilabel\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
      "File \u001B[1;32m~\\.virtualenvs\\DL4G-xN77NjMz\\lib\\site-packages\\sklearn\\metrics\\_classification.py:93\u001B[0m, in \u001B[0;36m_check_targets\u001B[1;34m(y_true, y_pred)\u001B[0m\n\u001B[0;32m     90\u001B[0m     y_type \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmulticlass\u001B[39m\u001B[38;5;124m\"\u001B[39m}\n\u001B[0;32m     92\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(y_type) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m---> 93\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m     94\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mClassification metrics can\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt handle a mix of \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m and \u001B[39m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;124m targets\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[0;32m     95\u001B[0m             type_true, type_pred\n\u001B[0;32m     96\u001B[0m         )\n\u001B[0;32m     97\u001B[0m     )\n\u001B[0;32m     99\u001B[0m \u001B[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001B[39;00m\n\u001B[0;32m    100\u001B[0m y_type \u001B[38;5;241m=\u001B[39m y_type\u001B[38;5;241m.\u001B[39mpop()\n",
      "\u001B[1;31mValueError\u001B[0m: Classification metrics can't handle a mix of multiclass and continuous targets"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow import keras\n",
    "\n",
    "model = keras.Sequential()\n",
    "dataset_dim = X_train.shape[1]\n",
    "\n",
    "model.add(keras.layers.Dense(37, activation='relu', input_shape=(dataset_dim,)))\n",
    "model.add(keras.layers.Dense(100, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='relu'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32)\n",
    "\n",
    "\n",
    "def plot_costs(costs):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(costs)\n",
    "    ax.set_title(\"Loss curve\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_costs(history.history[\"loss\"])\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "# f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy: %.4f\" % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
